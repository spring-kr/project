import os
import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¹œê·¼í•œ AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="centered"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "conversation" not in st.session_state:
    # ì¹œê·¼í•œ ëŒ€í™”ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
    prompt = PromptTemplate(
        input_variables=["history", "input"],
        template="""ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ AI ì±—ë´‡ì…ë‹ˆë‹¤.
        í•­ìƒ ë”°ëœ»í•˜ê³  ì´í•´ì‹¬ ìˆëŠ” íƒœë„ë¡œ ëŒ€í™”í•˜ë©°, ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë˜ ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šê²Œ ëŒ€í™”í•´ì£¼ì„¸ìš”.
        ì‚¬ìš©ìì˜ ê°ì •ì— ê³µê°í•˜ê³ , ì ì ˆí•œ ì´ëª¨í‹°ì½˜ë„ í™œìš©í•´ì£¼ì„¸ìš”.

        ì´ì „ ëŒ€í™”:
        {history}

        ì‚¬ìš©ì: {input}
        AI: """
    )

    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”
    llm = ChatOpenAI(
        temperature=float(os.getenv("TEMPERATURE", 0.7)),
        model_name=os.getenv("MODEL_NAME", "gpt-3.5-turbo"),
        max_tokens=int(os.getenv("MAX_TOKENS", 150))
    )

    # ConversationChain ì„¤ì •
    st.session_state.conversation = ConversationChain(
        llm=llm,
        memory=ConversationBufferMemory(),
        prompt=prompt,
        verbose=True
    )

# ì œëª© í‘œì‹œ
st.title("ì¹œê·¼í•œ AI ì±—ë´‡ ğŸ¤–")
st.markdown("""---
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ê³¼ ë”°ëœ»í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ì€ AI ì±—ë´‡ì…ë‹ˆë‹¤.
ë¬´ìŠ¨ ì´ì•¼ê¸°ë“  í¸í•˜ê²Œ ë‚˜ëˆ ì£¼ì„¸ìš”! ğŸ˜Š
---""")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.write(user_input)
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        ai_response = st.session_state.conversation.predict(input=user_input)
        st.write(ai_response)
    st.session_state.chat_history.append({"role": "assistant", "content": ai_response})